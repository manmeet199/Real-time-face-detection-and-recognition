{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0c856ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-13-5aa6a3e6c12c>:11: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Collect Images For Face Recognition\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_extractor(img):\n",
    "    faces = face_classifier.detectMultiScale(img, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    for (x,y,w,h) in faces:\n",
    "        x=x-10\n",
    "        y=y-10\n",
    "        cropped_face = img[y:y+h+50, x:x+w+50]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (400, 400))\n",
    "        #face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        file_name_path = './Images/' + str(count) + '.jpg'\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Face Cropper', face)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == 200: \n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f218accc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 4 classes.\n",
      "Found 394 images belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-b72e1b4a4ce2>:59: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  r = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "13/13 [==============================] - 190s 15s/step - loss: 0.9613 - accuracy: 0.7275 - val_loss: 0.1562 - val_accuracy: 0.9594\n",
      "Epoch 2/5\n",
      "13/13 [==============================] - 161s 13s/step - loss: 0.0342 - accuracy: 0.9900 - val_loss: 0.1253 - val_accuracy: 0.9569\n",
      "Epoch 3/5\n",
      "13/13 [==============================] - 162s 13s/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.2113 - val_accuracy: 0.9264\n",
      "Epoch 4/5\n",
      "13/13 [==============================] - 168s 13s/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1797 - val_accuracy: 0.9391\n",
      "Epoch 5/5\n",
      "13/13 [==============================] - 168s 13s/step - loss: 8.0179e-04 - accuracy: 1.0000 - val_loss: 0.1684 - val_accuracy: 0.9492\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# re-size all the images to this\n",
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "train_path = 'Datasets/Train'\n",
    "valid_path = 'Datasets/Test'\n",
    "\n",
    "# add preprocessing layer to the front of VGG\n",
    "vgg = VGG19(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "  \n",
    "folders = glob('Datasets/Train/*')\n",
    "x = Flatten()(vgg.output)\n",
    "\n",
    "\n",
    "prediction = Dense(len(folders), activation='softmax')(x)\n",
    "\n",
    "\n",
    "model = Model(inputs=vgg.input, outputs=prediction)\n",
    "\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                  horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('Datasets/Train',\n",
    "                                                  target_size = (224, 224),\n",
    "                                                  batch_size = 32,\n",
    "                                                  class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('Datasets/Test',\n",
    "                                             target_size = (224, 224),\n",
    "                                             batch_size = 32,\n",
    "                                             class_mode = 'categorical')\n",
    "\n",
    "r = model.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=5,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "model.save('facefeatures_new_model.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85402823",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:19: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:19: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-17-2b7901096d2e>:19: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if faces is ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000000e+00 1.0122636e-13 7.7870415e-20 1.3317031e-12]]\n",
      "[[1.0000000e+00 8.9826801e-13 1.5536190e-13 7.8954504e-10]]\n",
      "[[7.3212492e-01 9.7184092e-09 2.6183860e-12 2.6787513e-01]]\n",
      "[[9.9981433e-01 9.5703778e-10 1.3227876e-10 1.8573440e-04]]\n",
      "[[9.99999762e-01 1.75772811e-07 8.48984008e-11 1.11710726e-07]]\n",
      "[[1.0000000e+00 2.7186737e-09 1.2958010e-14 2.3063129e-10]]\n",
      "[[1.0000000e+00 1.8889035e-10 1.3976739e-13 1.5150132e-08]]\n",
      "[[1.0000000e+00 1.2171334e-12 4.2665080e-27 3.3155250e-15]]\n",
      "[[1.0000000e+00 1.9779934e-08 3.3407490e-24 1.5340230e-13]]\n",
      "[[1.0000000e+00 4.7853201e-09 4.4053586e-24 2.2886214e-11]]\n",
      "[[1.0000000e+00 2.0238180e-09 2.1020767e-26 3.3944536e-12]]\n",
      "[[1.0000000e+00 3.3384425e-13 1.0053461e-32 1.2060232e-15]]\n",
      "[[1.0000000e+00 1.5120285e-15 1.5582803e-33 4.3765184e-15]]\n",
      "[[1.0000000e+00 9.5467945e-17 3.5514413e-29 4.1794452e-17]]\n",
      "[[9.9997663e-01 2.8278349e-09 8.0113978e-19 2.3330411e-05]]\n",
      "[[1.0000000e+00 6.7799981e-11 3.0887263e-21 5.5738174e-12]]\n",
      "[[1.0000000e+00 1.1384785e-10 3.8280920e-20 2.0414803e-10]]\n",
      "[[1.0000000e+00 8.9439534e-10 1.8002993e-20 2.1148201e-08]]\n",
      "[[1.0000000e+00 8.0661558e-15 1.2707093e-21 4.5824967e-14]]\n",
      "[[9.9999988e-01 3.8168832e-10 7.6528690e-21 1.5970161e-07]]\n",
      "[[1.0000000e+00 1.9237623e-09 7.5150085e-24 2.1841252e-08]]\n",
      "[[1.0000000e+00 1.9778346e-12 2.2730742e-29 5.1301682e-17]]\n",
      "[[1.0000000e+00 3.6042167e-15 4.1239634e-34 3.4936318e-12]]\n",
      "[[1.0000000e+00 4.8704093e-18 3.4045843e-33 9.6744444e-14]]\n",
      "[[1.0000000e+00 2.9340073e-17 1.8177421e-30 8.4658483e-14]]\n",
      "[[1.0000000e+00 1.2209333e-11 2.4576554e-23 3.4879079e-11]]\n",
      "[[1.0000000e+00 9.6236220e-16 4.0226045e-30 1.3426548e-08]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from PIL import Image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import json\n",
    "import random\n",
    "import cv2\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import image\n",
    "model = load_model('facefeatures_new_model.h5')\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_extractor(img):\n",
    "    faces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    \n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "\n",
    "    return cropped_face\n",
    "\n",
    "# Doing some Face Recognition with the webcam\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    _, frame = video_capture.read()\n",
    "    face=face_extractor(frame)\n",
    "    if type(face) is np.ndarray:\n",
    "        face = cv2.resize(face, (224, 224))\n",
    "        im = Image.fromarray(face, 'RGB')\n",
    "        img_array = np.array(im)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        pred = model.predict(img_array)\n",
    "        print(pred)\n",
    "                     \n",
    "        name=\"None matching\"\n",
    "        \n",
    "        if(pred[0][0]>0.5):\n",
    "            name='Manmeet'\n",
    "           # cv2.putText(image, text, org, font, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])\n",
    "        cv2.putText(frame,name, (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "    else:\n",
    "        cv2.putText(frame,\"No face found\", (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "    cv2.imshow('Video', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813b6130",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
